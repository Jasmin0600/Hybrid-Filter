{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e5083970-4814-4a8e-9d50-42d52e8def24",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import ast\n",
    "from collections import Counter, defaultdict\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.model_selection import train_test_split\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "22c946c2-b24b-46d4-9647-9ac0edc94bfb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_275651/1084300144.py:29: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  item_similarity_df_metadata_thresholded = item_similarity_df_metadata.applymap(lambda x: x if x > 0.3 else 0)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "ratings = pd.read_csv(r'ratings_small_filtered_2.csv', index_col=0)\n",
    "All_parts_objects = pd.read_csv(r'All_parts_objects.csv', index_col=2)\n",
    "columns_to_keep = [str(i) for i in range(80)]\n",
    "movies_features = All_parts_objects[columns_to_keep]\n",
    "movies_metadata = pd.read_csv(r'movies_metadata_BERT_on_normal_tags_and_whisper.csv')\n",
    "\n",
    "unique_movieids_ratings = ratings['movieId'].unique()\n",
    "unique_movieids_movies_metadata = movies_metadata['movieId'].unique()\n",
    "unique_movieids_movies_features = movies_features.index.unique()\n",
    "common_movieids = list(set(unique_movieids_movies_metadata) & set(unique_movieids_ratings) & set(unique_movieids_movies_features))\n",
    "\n",
    "ratings = ratings[ratings['movieId'].isin(common_movieids)]\n",
    "movies_metadata = movies_metadata[movies_metadata['movieId'].isin(common_movieids)]\n",
    "movies_features = movies_features.iloc[movies_features.index.isin(common_movieids)]\n",
    "\n",
    "\n",
    "# Assuming ratings, movies_features, movies_metadata DataFrames are already loaded\n",
    "\n",
    "# Method 1: Collaborative Filtering\n",
    "user_item_matrix = ratings.pivot(index='userId', columns='movieId', values='rating')\n",
    "item_user_matrix_filled = user_item_matrix.T.fillna(0.5)\n",
    "item_similarity_cf = cosine_similarity(item_user_matrix_filled)\n",
    "item_similarity_df_cf = pd.DataFrame(item_similarity_cf, index=user_item_matrix.columns, columns=user_item_matrix.columns)\n",
    "\n",
    "# Method 2: Metadata-based Similarity\n",
    "item_metadata_matrix_filled = movies_features.fillna(0)\n",
    "item_similarity_metadata = cosine_similarity(item_metadata_matrix_filled)\n",
    "item_similarity_df_metadata = pd.DataFrame(item_similarity_metadata, index=item_metadata_matrix_filled.index, columns=item_metadata_matrix_filled.index)\n",
    "item_similarity_df_metadata_thresholded = item_similarity_df_metadata.applymap(lambda x: x if x > 0.3 else 0)\n",
    "\n",
    "# Method 3: BERT-based Similarity\n",
    "def string_to_array(s):\n",
    "    s = s.strip('[]')\n",
    "    return np.array([float(x) for x in s.split()])\n",
    "\n",
    "movies_metadata['bert_embedding'] = movies_metadata['bert_embedding'].apply(string_to_array)\n",
    "movie_embeddings = np.stack(movies_metadata['bert_embedding'].values)\n",
    "cosine_sim_bert = cosine_similarity(movie_embeddings, movie_embeddings)\n",
    "item_similarity_df_bert = pd.DataFrame(cosine_sim_bert, index=movies_metadata['movieId'], columns=movies_metadata['movieId'])\n",
    "\n",
    "# Split the ratings data into training and testing sets\n",
    "train_ratings, test_ratings = train_test_split(ratings, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "62a2dd6d-f46f-4a94-80b1-40b583dcc989",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results for k=5:\n",
      "Average Precision@5: 0.1063\n",
      "Average Recall@5: 0.0030\n",
      "\n",
      "Results for k=10:\n",
      "Average Precision@10: 0.1392\n",
      "Average Recall@10: 0.0020\n",
      "\n",
      "Results for k=20:\n",
      "Average Precision@20: 0.1617\n",
      "Average Recall@20: 0.0013\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Function to get top-k recommendations from a similarity matrix\n",
    "def get_top_k_recommendations(similarity_matrix, item_id, k):\n",
    "    similar_items = similarity_matrix.loc[item_id].sort_values(ascending=False)[1:k+1].index.tolist()\n",
    "    return similar_items\n",
    "\n",
    "# Function to merge recommendations from all three methods\n",
    "def get_merged_recommendations(item_id, k):\n",
    "    rec_cf = get_top_k_recommendations(item_similarity_df_cf, item_id, k)\n",
    "    rec_metadata = get_top_k_recommendations(item_similarity_df_metadata_thresholded, item_id, k)\n",
    "    rec_bert = get_top_k_recommendations(item_similarity_df_bert, item_id, k)\n",
    "    \n",
    "    # Combine and remove duplicates\n",
    "    merged_rec = list(dict.fromkeys(rec_cf + rec_metadata + rec_bert))\n",
    "    return merged_rec[:k]\n",
    "\n",
    "def precision_recall_at_k(test_data, k=10, threshold=3.5):\n",
    "    \"\"\"Return precision and recall at k metrics for each user\"\"\"\n",
    "    \n",
    "    user_est_true = defaultdict(list)\n",
    "    for _, row in test_data.iterrows():\n",
    "        uid, movie_id, true_r = row['userId'], row['movieId'], row['rating']\n",
    "        recommended_items = get_merged_recommendations(movie_id, k)\n",
    "        \n",
    "        # Get the actual ratings for recommended items\n",
    "        for rec_item in recommended_items:\n",
    "            est_r = test_data[(test_data['userId'] == uid) & (test_data['movieId'] == rec_item)]['rating'].values\n",
    "            if len(est_r) > 0:\n",
    "                user_est_true[uid].append((est_r[0], true_r))\n",
    "            else:\n",
    "                user_est_true[uid].append((0, true_r))  # If no rating exists, assume 0\n",
    "    \n",
    "    precisions = dict()\n",
    "    recalls = dict()\n",
    "    for uid, user_ratings in user_est_true.items():\n",
    "        # Number of relevant items\n",
    "        n_rel = sum((true_r >= threshold) for (_, true_r) in user_ratings)\n",
    "        \n",
    "        # Number of recommended items in top k\n",
    "        n_rec_k = sum((est >= threshold) for (est, _) in user_ratings[:k])\n",
    "        \n",
    "        # Number of relevant and recommended items in top k\n",
    "        n_rel_and_rec_k = sum(\n",
    "            ((true_r >= threshold) and (est >= threshold))\n",
    "            for (est, true_r) in user_ratings[:k]\n",
    "        )\n",
    "        \n",
    "        # Precision@K: Proportion of recommended items that are relevant\n",
    "        precisions[uid] = n_rel_and_rec_k / n_rec_k if n_rec_k != 0 else 0\n",
    "        \n",
    "        # Recall@K: Proportion of relevant items that are recommended\n",
    "        recalls[uid] = n_rel_and_rec_k / n_rel if n_rel != 0 else 0\n",
    "    \n",
    "    return precisions, recalls\n",
    "\n",
    "# Evaluate the model\n",
    "k_values = [5, 10, 20]\n",
    "threshold = 3.5\n",
    "\n",
    "for k in k_values:\n",
    "    precisions, recalls = precision_recall_at_k(test_ratings, k=k, threshold=threshold)\n",
    "    \n",
    "    avg_precision = sum(prec for prec in precisions.values()) / len(precisions)\n",
    "    avg_recall = sum(rec for rec in recalls.values()) / len(recalls)\n",
    "    \n",
    "    print(f\"Results for k={k}:\")\n",
    "    print(f\"Average Precision@{k}: {avg_precision:.4f}\")\n",
    "    print(f\"Average Recall@{k}: {avg_recall:.4f}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a80a3272-fb76-4841-9a83-095f96633bc8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results for k=50:\n",
      "Average Precision@50: 0.1901\n",
      "Average Recall@50: 0.0006\n",
      "\n",
      "Results for k=100:\n",
      "Average Precision@100: 0.2126\n",
      "Average Recall@100: 0.0003\n",
      "\n",
      "Results for k=150:\n",
      "Average Precision@150: 0.2201\n",
      "Average Recall@150: 0.0002\n",
      "\n",
      "Results for k=255:\n",
      "Average Precision@255: 0.2305\n",
      "Average Recall@255: 0.0002\n",
      "\n",
      "Results for k=350:\n",
      "Average Precision@350: 0.2410\n",
      "Average Recall@350: 0.0001\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Function to get top-k recommendations from a similarity matrix\n",
    "def get_top_k_recommendations(similarity_matrix, item_id, k):\n",
    "    similar_items = similarity_matrix.loc[item_id].sort_values(ascending=False)[1:k+1].index.tolist()\n",
    "    return similar_items\n",
    "\n",
    "# Function to merge recommendations from all three methods\n",
    "def get_merged_recommendations(item_id, k):\n",
    "    rec_cf = get_top_k_recommendations(item_similarity_df_cf, item_id, k)\n",
    "    rec_metadata = get_top_k_recommendations(item_similarity_df_metadata_thresholded, item_id, k)\n",
    "    rec_bert = get_top_k_recommendations(item_similarity_df_bert, item_id, k)\n",
    "    \n",
    "    # Combine and remove duplicates\n",
    "    merged_rec = list(dict.fromkeys(rec_cf + rec_metadata + rec_bert))\n",
    "    return merged_rec[:k]\n",
    "\n",
    "def precision_recall_at_k(test_data, k=10, threshold=3.5):\n",
    "    \"\"\"Return precision and recall at k metrics for each user\"\"\"\n",
    "    \n",
    "    user_est_true = defaultdict(list)\n",
    "    for _, row in test_data.iterrows():\n",
    "        uid, movie_id, true_r = row['userId'], row['movieId'], row['rating']\n",
    "        recommended_items = get_merged_recommendations(movie_id, k)\n",
    "        \n",
    "        # Get the actual ratings for recommended items\n",
    "        for rec_item in recommended_items:\n",
    "            est_r = test_data[(test_data['userId'] == uid) & (test_data['movieId'] == rec_item)]['rating'].values\n",
    "            if len(est_r) > 0:\n",
    "                user_est_true[uid].append((est_r[0], true_r))\n",
    "            else:\n",
    "                user_est_true[uid].append((0, true_r))  # If no rating exists, assume 0\n",
    "    \n",
    "    precisions = dict()\n",
    "    recalls = dict()\n",
    "    for uid, user_ratings in user_est_true.items():\n",
    "        # Number of relevant items\n",
    "        n_rel = sum((true_r >= threshold) for (_, true_r) in user_ratings)\n",
    "        \n",
    "        # Number of recommended items in top k\n",
    "        n_rec_k = sum((est >= threshold) for (est, _) in user_ratings[:k])\n",
    "        \n",
    "        # Number of relevant and recommended items in top k\n",
    "        n_rel_and_rec_k = sum(\n",
    "            ((true_r >= threshold) and (est >= threshold))\n",
    "            for (est, true_r) in user_ratings[:k]\n",
    "        )\n",
    "        \n",
    "        # Precision@K: Proportion of recommended items that are relevant\n",
    "        precisions[uid] = n_rel_and_rec_k / n_rec_k if n_rec_k != 0 else 0\n",
    "        \n",
    "        # Recall@K: Proportion of relevant items that are recommended\n",
    "        recalls[uid] = n_rel_and_rec_k / n_rel if n_rel != 0 else 0\n",
    "    \n",
    "    return precisions, recalls\n",
    "\n",
    "# Evaluate the model\n",
    "k_values = [50,100,150,255,350]\n",
    "threshold = 3.5\n",
    "\n",
    "for k in k_values:\n",
    "    precisions, recalls = precision_recall_at_k(test_ratings, k=k, threshold=threshold)\n",
    "    \n",
    "    avg_precision = sum(prec for prec in precisions.values()) / len(precisions)\n",
    "    avg_recall = sum(rec for rec in recalls.values()) / len(recalls)\n",
    "    \n",
    "    print(f\"Results for k={k}:\")\n",
    "    print(f\"Average Precision@{k}: {avg_precision:.4f}\")\n",
    "    print(f\"Average Recall@{k}: {avg_recall:.4f}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecf8bc40-100d-485e-a8a3-2de76a5d9fcb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
